{\rtf1\ansi\ansicpg1251\cocoartf2512
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red25\green25\blue25;\red255\green255\blue255;\red0\green0\blue0;
}
{\*\expandedcolortbl;;\cssrgb\c12941\c12941\c12941;\cssrgb\c100000\c100000\c100000;\cssrgb\c0\c0\c0;
}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 2020-09-29 20:45:37.113615: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\
2020-09-29 20:45:40.529439: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\
2020-09-29 20:45:40.575932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\
2020-09-29 20:45:40.576507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \
pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\
2020-09-29 20:45:40.576563: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\
2020-09-29 20:45:40.827543: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\
2020-09-29 20:45:40.952645: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\
2020-09-29 20:45:40.974030: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\
2020-09-29 20:45:41.267427: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\
2020-09-29 20:45:41.321113: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\
2020-09-29 20:45:41.835468: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\
2020-09-29 20:45:41.835642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\
2020-09-29 20:45:41.836295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\
2020-09-29 20:45:41.836806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\
2020-09-29 20:45:41.871785: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\
2020-09-29 20:45:41.872001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3042a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\
2020-09-29 20:45:41.872033: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\
2020-09-29 20:45:42.044316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\
2020-09-29 20:45:42.045082: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x30439c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\
2020-09-29 20:45:42.045111: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\
2020-09-29 20:45:42.046468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\
2020-09-29 20:45:42.046975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \
pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\
2020-09-29 20:45:42.047016: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\
2020-09-29 20:45:42.047058: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\
2020-09-29 20:45:42.047077: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\
2020-09-29 20:45:42.047099: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\
2020-09-29 20:45:42.047116: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\
2020-09-29 20:45:42.047133: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\
2020-09-29 20:45:42.047150: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\
2020-09-29 20:45:42.047228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\
2020-09-29 20:45:42.047757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\
2020-09-29 20:45:42.048247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\
2020-09-29 20:45:42.051853: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\
2020-09-29 20:45:46.051087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\
2020-09-29 20:45:46.051152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \
2020-09-29 20:45:46.051172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \
2020-09-29 20:45:46.056437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\
2020-09-29 20:45:46.057041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\
2020-09-29 20:45:46.057589: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\
2020-09-29 20:45:46.057639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14968 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\
WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\
Downloading data from {\field{\*\fldinst{HYPERLINK "https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5}}\
9412608/9406464 [==============================] - 0s 0us/step\
2020-09-29 20:45:48.354266: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\
2020-09-29 20:45:48.358481: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1391] Profiler found 1 GPUs\
2020-09-29 20:45:48.403671: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcupti.so.10.1\
2020-09-29 20:45:48.595036: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1513] CUPTI activity buffer flushed\
\
Epoch 00001: LearningRateScheduler reducing learning rate to 0.0.\
Epoch 1/50\
2020-09-29 20:45:50.813780: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\
2020-09-29 20:45:52.915031: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\
      1/Unknown - 0s 112us/step - loss: 2.2363 - categorical_accuracy: 0.17192020-09-29 20:45:58.409316: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\
Instructions for updating:\
use `tf.profiler.experimental.stop` instead.\
2020-09-29 20:45:58.464896: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1513] CUPTI activity buffer flushed\
2020-09-29 20:45:58.475489: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:223]  GpuTracer has collected 280 callback api events and 280 activity events. \
2020-09-29 20:45:58.519892: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /content/drive/My Drive/log16/train/plugins/profile/2020_09_29_20_45_58\
2020-09-29 20:45:58.536291: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to /content/drive/My Drive/log16/train/plugins/profile/2020_09_29_20_45_58/ef808496da6f.trace.json.gz\
2020-09-29 20:45:58.574687: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /content/drive/My Drive/log16/train/plugins/profile/2020_09_29_20_45_58\
2020-09-29 20:45:58.584138: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to /content/drive/My Drive/log16/train/plugins/profile/2020_09_29_20_45_58/ef808496da6f.memory_profile.json.gz\
2020-09-29 20:45:58.608460: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: /content/drive/My Drive/log16/train/plugins/profile/2020_09_29_20_45_58Dumped tool data for xplane.pb to /content/drive/My Drive/log16/train/plugins/profile/2020_09_29_20_45_58/ef808496da6f.xplane.pb\
Dumped tool data for overview_page.pb to /content/drive/My Drive/log16/train/plugins/profile/2020_09_29_20_45_58/ef808496da6f.overview_page.pb\
Dumped tool data for input_pipeline.pb to /content/drive/My Drive/log16/train/plugins/profile/2020_09_29_20_45_58/ef808496da6f.input_pipeline.pb\
Dumped tool data for tensorflow_stats.pb to /content/drive/My Drive/log16/train/plugins/profile/2020_09_29_20_45_58/ef808496da6f.tensorflow_stats.pb\
Dumped tool data for kernel_stats.pb to /content/drive/My Drive/log16/train/plugins/profile/2020_09_29_20_45_58/ef808496da6f.kernel_stats.pb\
\
      2/Unknown - 0s 102ms/step - loss: 2.2553 - categorical_accuracy: 0.1172WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0518s vs `on_train_batch_end` time: 0.1509s). Check your callbacks.\
220/220 [==============================] - 55s 251ms/step - loss: 1.9153 - categorical_accuracy: 0.1693 - val_loss: 1.8719 - val_categorical_accuracy: 0.1680\
\
Epoch 00002: LearningRateScheduler reducing learning rate to 1.25e-06.\
Epoch 2/50\
220/220 [==============================] - 27s 121ms/step - loss: 1.9095 - categorical_accuracy: 0.1674 - val_loss: 1.8366 - val_categorical_accuracy: 0.1700\
\
Epoch 00003: LearningRateScheduler reducing learning rate to 2.5e-06.\
Epoch 3/50\
220/220 [==============================] - 27s 121ms/step - loss: 1.8647 - categorical_accuracy: 0.1670 - val_loss: 1.7725 - val_categorical_accuracy: 0.1747\
\
Epoch 00004: LearningRateScheduler reducing learning rate to 3.7500000000000005e-06.\
Epoch 4/50\
220/220 [==============================] - 27s 122ms/step - loss: 1.7942 - categorical_accuracy: 0.1676 - val_loss: 1.6892 - val_categorical_accuracy: 0.1787\
\
Epoch 00005: LearningRateScheduler reducing learning rate to 5e-06.\
Epoch 5/50\
220/220 [==============================] - 26s 120ms/step - loss: 1.7268 - categorical_accuracy: 0.1765 - val_loss: 1.5959 - val_categorical_accuracy: 0.1933\
\
Epoch 00006: LearningRateScheduler reducing learning rate to 6.25e-06.\
Epoch 6/50\
220/220 [==============================] - 27s 122ms/step - loss: 1.6285 - categorical_accuracy: 0.1853 - val_loss: 1.5006 - val_categorical_accuracy: 0.2147\
\
Epoch 00007: LearningRateScheduler reducing learning rate to 7.500000000000001e-06.\
Epoch 7/50\
220/220 [==============================] - 27s 121ms/step - loss: 1.5458 - categorical_accuracy: 0.2058 - val_loss: 1.4077 - val_categorical_accuracy: 0.2493\
\
Epoch 00008: LearningRateScheduler reducing learning rate to 8.750000000000001e-06.\
Epoch 8/50\
220/220 [==============================] - 27s 121ms/step - loss: 1.4654 - categorical_accuracy: 0.2324 - val_loss: 1.3183 - val_categorical_accuracy: 0.2813\
\
Epoch 00009: LearningRateScheduler reducing learning rate to 1e-05.\
Epoch 9/50\
220/220 [==============================] - 27s 122ms/step - loss: 1.3830 - categorical_accuracy: 0.2647 - val_loss: 1.2326 - val_categorical_accuracy: 0.3167\
\
Epoch 00010: LearningRateScheduler reducing learning rate to 1.6529888822158655e-06.\
Epoch 10/50\
220/220 [==============================] - 28s 126ms/step - loss: 1.3036 - categorical_accuracy: 0.2882 - val_loss: 1.2197 - val_categorical_accuracy: 0.3223\
\
Epoch 00011: LearningRateScheduler reducing learning rate to 1.353352832366127e-06.\
Epoch 11/50\
220/220 [==============================] - 27s 123ms/step - loss: 1.2939 - categorical_accuracy: 0.2934 - val_loss: 1.2091 - val_categorical_accuracy: 0.3317\
\
Epoch 00012: LearningRateScheduler reducing learning rate to 1.1080315836233389e-06.\
Epoch 12/50\
220/220 [==============================] - 27s 122ms/step - loss: 1.2778 - categorical_accuracy: 0.2998 - val_loss: 1.2003 - val_categorical_accuracy: 0.3350\
\
Epoch 00013: LearningRateScheduler reducing learning rate to 9.071795328941247e-07.\
Epoch 13/50\
220/220 [==============================] - 27s 121ms/step - loss: 1.2704 - categorical_accuracy: 0.3058 - val_loss: 1.1932 - val_categorical_accuracy: 0.3397\
\
Epoch 00014: LearningRateScheduler reducing learning rate to 7.427357821433388e-07.\
Epoch 14/50\
220/220 [==============================] - 27s 121ms/step - loss: 1.2665 - categorical_accuracy: 0.3102 - val_loss: 1.1873 - val_categorical_accuracy: 0.3430\
\
Epoch 00015: LearningRateScheduler reducing learning rate to 6.081006262521796e-07.\
Epoch 15/50\
220/220 [==============================] - 27s 124ms/step - loss: 1.2544 - categorical_accuracy: 0.3150 - val_loss: 1.1825 - val_categorical_accuracy: 0.3450\
\
Epoch 00016: LearningRateScheduler reducing learning rate to 4.978706836786395e-07.\
Epoch 16/50\
220/220 [==============================] - 27s 121ms/step - loss: 1.2580 - categorical_accuracy: 0.3125 - val_loss: 1.1785 - val_categorical_accuracy: 0.3480\
\
Epoch 00017: LearningRateScheduler reducing learning rate to 4.0762203978366216e-07.\
Epoch 17/50\
220/220 [==============================] - 27s 121ms/step - loss: 1.2553 - categorical_accuracy: 0.3133 - val_loss: 1.1752 - val_categorical_accuracy: 0.3490\
\
Epoch 00018: LearningRateScheduler reducing learning rate to 3.337326996032607e-07.\
Epoch 18/50\
220/220 [==============================] - 27s 122ms/step - loss: 1.2478 - categorical_accuracy: 0.3176 - val_loss: 1.1725 - val_categorical_accuracy: 0.3517\
\
Epoch 00019: LearningRateScheduler reducing learning rate to 2.732372244729256e-07.\
Epoch 19/50\
220/220 [==============================] - 27s 121ms/step - loss: 1.2457 - categorical_accuracy: 0.3142 - val_loss: 1.1702 - val_categorical_accuracy: 0.3533\
\
Epoch 00020: LearningRateScheduler reducing learning rate to 2.2370771856165592e-07.\
Epoch 20/50\
220/220 [==============================] - 27s 122ms/step - loss: 1.2450 - categorical_accuracy: 0.3172 - val_loss: 1.1684 - val_categorical_accuracy: 0.3553\
\
Epoch 00021: LearningRateScheduler reducing learning rate to 1.831563888873418e-07.\
Epoch 21/50\
220/220 [==============================] - 27s 122ms/step - loss: 1.2426 - categorical_accuracy: 0.3154 - val_loss: 1.1669 - val_categorical_accuracy: 0.3557\
\
Epoch 00022: LearningRateScheduler reducing learning rate to 1.4995576820477705e-07.\
Epoch 22/50\
220/220 [==============================] - 27s 123ms/step - loss: 1.2412 - categorical_accuracy: 0.3140 - val_loss: 1.1656 - val_categorical_accuracy: 0.3557\
\
Epoch 00023: LearningRateScheduler reducing learning rate to 1.2277339903068438e-07.\
Epoch 23/50\
220/220 [==============================] - 27s 121ms/step - loss: 1.2392 - categorical_accuracy: 0.3182 - val_loss: 1.1646 - val_categorical_accuracy: 0.3557\
\
Epoch 00024: LearningRateScheduler reducing learning rate to 1.0051835744633576e-07.\
Epoch 24/50\
220/220 [==============================] - 27s 122ms/step - loss: 1.2342 - categorical_accuracy: 0.3187 - val_loss: 1.1638 - val_categorical_accuracy: 0.3563\
\
Epoch 00025: LearningRateScheduler reducing learning rate to 8.229747049020024e-08.\
Epoch 25/50\
220/220 [==============================] - 27s 122ms/step - loss: 1.2351 - categorical_accuracy: 0.3184 - val_loss: 1.1631 - val_categorical_accuracy: 0.3567\
\
Epoch 00026: LearningRateScheduler reducing learning rate to 6.737946999085467e-08.\
Epoch 26/50\
220/220 [==============================] - 27s 122ms/step - loss: 1.2380 - categorical_accuracy: 0.3180 - val_loss: 1.1625 - val_categorical_accuracy: 0.3573\
\
Epoch 00027: LearningRateScheduler reducing learning rate to 5.516564420760772e-08.\
Epoch 27/50\
220/220 [==============================] - 27s 123ms/step - loss: 1.2323 - categorical_accuracy: 0.3224 - val_loss: 1.1621 - val_categorical_accuracy: 0.3573\
\
Epoch 00028: LearningRateScheduler reducing learning rate to 4.516580942612666e-08.\
Epoch 28/50\
220/220 [==============================] - 26s 120ms/step - loss: 1.2352 - categorical_accuracy: 0.3197 - val_loss: 1.1617 - val_categorical_accuracy: 0.3577\
\
Epoch 00029: LearningRateScheduler reducing learning rate to 3.697863716482929e-08.\
Epoch 29/50\
220/220 [==============================] - 26s 120ms/step - loss: 1.2303 - categorical_accuracy: 0.3234 - val_loss: 1.1614 - val_categorical_accuracy: 0.3577\
\
Epoch 00030: LearningRateScheduler reducing learning rate to 3.027554745375813e-08.\
Epoch 30/50\
220/220 [==============================] - 27s 122ms/step - loss: 1.2364 - categorical_accuracy: 0.3204 - val_loss: 1.1611 - val_categorical_accuracy: 0.3577\
\
Epoch 00031: LearningRateScheduler reducing learning rate to 2.4787521766663585e-08.\
Epoch 31/50\
220/220 [==============================] - 27s 121ms/step - loss: 1.2267 - categorical_accuracy: 0.3239 - val_loss: 1.1609 - val_categorical_accuracy: 0.3580\
\
Epoch 00032: LearningRateScheduler reducing learning rate to 2.029430636295734e-08.\
Epoch 32/50\
220/220 [==============================] - 27s 121ms/step - loss: 1.2326 - categorical_accuracy: 0.3245 - val_loss: 1.1607 - val_categorical_accuracy: 0.3583\
\
Epoch 00033: LearningRateScheduler reducing learning rate to 1.661557273173934e-08.\
Epoch 33/50\
220/220 [==============================] - 28s 125ms/step - loss: 1.2319 - categorical_accuracy: 0.3217 - val_loss: 1.1606 - val_categorical_accuracy: 0.3583\
\
Epoch 00034: LearningRateScheduler reducing learning rate to 1.3603680375478929e-08.\
Epoch 34/50\
220/220 [==============================] - 26s 120ms/step - loss: 1.2309 - categorical_accuracy: 0.3205 - val_loss: 1.1605 - val_categorical_accuracy: 0.3583\
\
Epoch 00035: LearningRateScheduler reducing learning rate to 1.1137751478448025e-08.\
Epoch 35/50\
220/220 [==============================] - 27s 120ms/step - loss: 1.2320 - categorical_accuracy: 0.3256 - val_loss: 1.1604 - val_categorical_accuracy: 0.3587\
\
Epoch 00036: LearningRateScheduler reducing learning rate to 9.118819655545162e-09.\
Epoch 36/50\
220/220 [==============================] - 27s 122ms/step - loss: 1.2297 - categorical_accuracy: 0.3236 - val_loss: 1.1603 - val_categorical_accuracy: 0.3587\
\
Epoch 00037: LearningRateScheduler reducing learning rate to 7.465858083766792e-09.\
Epoch 37/50\
220/220 [==============================] - 26s 120ms/step - loss: 1.2293 - categorical_accuracy: 0.3225 - val_loss: 1.1602 - val_categorical_accuracy: 0.3587\
\
Epoch 00038: LearningRateScheduler reducing learning rate to 6.1125276112957235e-09.\
Epoch 38/50\
220/220 [==============================] - 27s 122ms/step - loss: 1.2333 - categorical_accuracy: 0.3212 - val_loss: 1.1602 - val_categorical_accuracy: 0.3587\
\
Epoch 00039: LearningRateScheduler reducing learning rate to 5.004514334406104e-09.\
Epoch 39/50\
220/220 [==============================] - 27s 122ms/step - loss: 1.2342 - categorical_accuracy: 0.3211 - val_loss: 1.1601 - val_categorical_accuracy: 0.3587\
\
Epoch 00040: LearningRateScheduler reducing learning rate to 4.0973497897978646e-09.\
Epoch 40/50\
220/220 [==============================] - 27s 121ms/step - loss: 1.2337 - categorical_accuracy: 0.3186 - val_loss: 1.1601 - val_categorical_accuracy: 0.3587\
\
Epoch 00041: LearningRateScheduler reducing learning rate to 3.354626279025119e-09.\
Epoch 41/50\
220/220 [==============================] - 27s 121ms/step - loss: 1.2338 - categorical_accuracy: 0.3200 - val_loss: 1.1601 - val_categorical_accuracy: 0.3587\
\
Epoch 00042: LearningRateScheduler reducing learning rate to 2.7465356997214206e-09.\
Epoch 42/50\
220/220 [==============================] - 27s 121ms/step - loss: 1.2304 - categorical_accuracy: 0.3239 - val_loss: 1.1600 - val_categorical_accuracy: 0.3587\
\
Epoch 00043: LearningRateScheduler reducing learning rate to 2.248673241788482e-09.\
Epoch 43/50\
220/220 [==============================] - 26s 120ms/step - loss: 1.2287 - categorical_accuracy: 0.3264 - val_loss: 1.1600 - val_categorical_accuracy: 0.3587\
\
Epoch 00044: LearningRateScheduler reducing learning rate to 1.841057936675792e-09.\
Epoch 44/50\
220/220 [==============================] - 27s 121ms/step - loss: 1.2267 - categorical_accuracy: 0.3281 - val_loss: 1.1600 - val_categorical_accuracy: 0.3587\
\
Epoch 00045: LearningRateScheduler reducing learning rate to 1.5073307509547652e-09.\
Epoch 45/50\
220/220 [==============================] - 27s 124ms/step - loss: 1.2363 - categorical_accuracy: 0.3122 - val_loss: 1.1600 - val_categorical_accuracy: 0.3587\
\
Epoch 00046: LearningRateScheduler reducing learning rate to 1.2340980408667958e-09.\
Epoch 46/50\
220/220 [==============================] - 26s 120ms/step - loss: 1.2316 - categorical_accuracy: 0.3217 - val_loss: 1.1600 - val_categorical_accuracy: 0.3587\
\
Epoch 00047: LearningRateScheduler reducing learning rate to 1.0103940183709325e-09.\
Epoch 47/50\
220/220 [==============================] - 27s 121ms/step - loss: 1.2356 - categorical_accuracy: 0.3209 - val_loss: 1.1600 - val_categorical_accuracy: 0.3587\
\
Epoch 00048: LearningRateScheduler reducing learning rate to 8.272406555663223e-10.\
Epoch 48/50\
220/220 [==============================] - 27s 121ms/step - loss: 1.2332 - categorical_accuracy: 0.3206 - val_loss: 1.1600 - val_categorical_accuracy: 0.3587\
\
Epoch 00049: LearningRateScheduler reducing learning rate to 6.772873649085378e-10.\
Epoch 49/50\
220/220 [==============================] - 27s 121ms/step - loss: 1.2355 - categorical_accuracy: 0.3204 - val_loss: 1.1600 - val_categorical_accuracy: 0.3587\
\
Epoch 00050: LearningRateScheduler reducing learning rate to 5.545159943217695e-10.\
Epoch 50/50\
220/220 [==============================] - 26s 120ms/step - loss: 1.2325 - categorical_accuracy: 0.3209 - val_loss: 1.1600 - val_categorical_accuracy: 0.3587}