{\rtf1\ansi\ansicpg1251\cocoartf2512
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red144\green1\blue18;\red255\green255\blue254;\red0\green0\blue0;
\red0\green0\blue255;\red19\green118\blue70;}
{\*\expandedcolortbl;;\cssrgb\c63922\c8235\c8235;\cssrgb\c100000\c100000\c99608;\cssrgb\c0\c0\c0;
\cssrgb\c0\c0\c100000;\cssrgb\c3529\c52549\c34510;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sl380\partightenfactor0

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 """This module implements data feeding and training loop to create model\cf4 \cb1 \strokec4 \
\cf2 \cb3 \strokec2 to classify X-Ray chest images as a lab example for BSU students.\cf4 \cb1 \strokec4 \
\cf2 \cb3 \strokec2 """\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\sl380\partightenfactor0
\cf4 \cb3 __author__ = \cf2 \strokec2 'Alexander Soroka, soroka.a.m@gmail.com'\cf4 \cb1 \strokec4 \
\cb3 __copyright__ = \cf2 \strokec2 """Copyright 2020 Alexander Soroka"""\cf4 \cb1 \strokec4 \
\
\
\pard\pardeftab720\sl380\partightenfactor0
\cf5 \cb3 \strokec5 import\cf4 \strokec4  argparse\cb1 \
\cf5 \cb3 \strokec5 import\cf4 \strokec4  glob\cb1 \
\cf5 \cb3 \strokec5 import\cf4 \strokec4  numpy \cf5 \strokec5 as\cf4 \strokec4  np\cb1 \
\cf5 \cb3 \strokec5 import\cf4 \strokec4  tensorflow \cf5 \strokec5 as\cf4 \strokec4  tf\cb1 \
\cf5 \cb3 \strokec5 import\cf4 \strokec4  time\cb1 \
\cf5 \cb3 \strokec5 from\cf4 \strokec4  tensorflow.python \cf5 \strokec5 import\cf4 \strokec4  keras \cf5 \strokec5 as\cf4 \strokec4  keras\cb1 \
\cf5 \cb3 \strokec5 from\cf4 \strokec4  tensorflow.python.keras.callbacks \cf5 \strokec5 import\cf4 \strokec4  LearningRateScheduler\cb1 \
\
\
\pard\pardeftab720\sl380\partightenfactor0
\cf4 \cb3 LOG_DIR = \cf2 \strokec2 'logs'\cf4 \cb1 \strokec4 \
\cb3 SHUFFLE_BUFFER = \cf6 \strokec6 4\cf4 \cb1 \strokec4 \
\cb3 BATCH_SIZE = \cf6 \strokec6 64\cf4 \cb1 \strokec4 \
\cb3 NUM_CLASSES = \cf6 \strokec6 6\cf4 \cb1 \strokec4 \
\cb3 PARALLEL_CALLS=\cf6 \strokec6 4\cf4 \cb1 \strokec4 \
\cb3 RESIZE_TO = \cf6 \strokec6 224\cf4 \cb1 \strokec4 \
\cb3 TRAINSET_SIZE = \cf6 \strokec6 14034\cf4 \cb1 \strokec4 \
\cb3 VALSET_SIZE = \cf6 \strokec6 3000\cf4 \cb1 \strokec4 \
\
\
\pard\pardeftab720\sl380\partightenfactor0
\cf5 \cb3 \strokec5 def\cf4 \strokec4  parse_proto_example(proto):\cb1 \
\pard\pardeftab720\sl380\partightenfactor0
\cf4 \cb3     keys_to_features = \{\cb1 \
\cb3         \cf2 \strokec2 'image/encoded'\cf4 \strokec4 : tf.io.FixedLenFeature((), tf.string, default_value=\cf2 \strokec2 ''\cf4 \strokec4 ),\cb1 \
\cb3         \cf2 \strokec2 'image/class/label'\cf4 \strokec4 : tf.io.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64))\cb1 \
\cb3     \}\cb1 \
\cb3     example = tf.io.parse_single_example(proto, keys_to_features)\cb1 \
\cb3     example[\cf2 \strokec2 'image'\cf4 \strokec4 ] = tf.image.decode_jpeg(example[\cf2 \strokec2 'image/encoded'\cf4 \strokec4 ], channels=\cf6 \strokec6 3\cf4 \strokec4 )\cb1 \
\cb3     example[\cf2 \strokec2 'image'\cf4 \strokec4 ] = tf.image.convert_image_dtype(example[\cf2 \strokec2 'image'\cf4 \strokec4 ], dtype=tf.float32)\cb1 \
\cb3     example[\cf2 \strokec2 'image'\cf4 \strokec4 ] = tf.image.resize(example[\cf2 \strokec2 'image'\cf4 \strokec4 ], tf.constant([RESIZE_TO, RESIZE_TO]))\cb1 \
\cb3     \cf5 \strokec5 return\cf4 \strokec4  example[\cf2 \strokec2 'image'\cf4 \strokec4 ], tf.one_hot(example[\cf2 \strokec2 'image/class/label'\cf4 \strokec4 ], depth=NUM_CLASSES)\cb1 \
\
\
\pard\pardeftab720\sl380\partightenfactor0
\cf5 \cb3 \strokec5 def\cf4 \strokec4  normalize(image, label):\cb1 \
\pard\pardeftab720\sl380\partightenfactor0
\cf4 \cb3     \cf5 \strokec5 return\cf4 \strokec4  tf.image.per_image_standardization(image), label\cb1 \
\
\pard\pardeftab720\sl380\partightenfactor0
\cf5 \cb3 \strokec5 def\cf4 \strokec4  resize(image, label):\cb1 \
\pard\pardeftab720\sl380\partightenfactor0
\cf4 \cb3     \cf5 \strokec5 return\cf4 \strokec4  tf.image.resize(image, tf.constant([RESIZE_TO, RESIZE_TO])), label\cb1 \
\
\pard\pardeftab720\sl380\partightenfactor0
\cf5 \cb3 \strokec5 def\cf4 \strokec4  create_dataset(filenames, batch_size):\cb1 \
\pard\pardeftab720\sl380\partightenfactor0
\cf4 \cb3     \cf2 \strokec2 """Create dataset from tfrecords file\cf4 \cb1 \strokec4 \
\pard\pardeftab720\sl380\partightenfactor0
\cf2 \cb3 \strokec2     :tfrecords_files: Mask to collect tfrecords file of dataset\cf4 \cb1 \strokec4 \
\cf2 \cb3 \strokec2     :returns: tf.data.Dataset\cf4 \cb1 \strokec4 \
\cf2 \cb3 \strokec2     """\cf4 \cb1 \strokec4 \
\pard\pardeftab720\sl380\partightenfactor0
\cf4 \cb3     \cf5 \strokec5 return\cf4 \strokec4  tf.data.TFRecordDataset(filenames)\\\cb1 \
\cb3         .\cf5 \strokec5 map\cf4 \strokec4 (parse_proto_example)\\\cb1 \
\cb3         .\cf5 \strokec5 map\cf4 \strokec4 (resize)\\\cb1 \
\cb3         .\cf5 \strokec5 map\cf4 \strokec4 (normalize)\\\cb1 \
\cb3         .batch(batch_size)\\\cb1 \
\cb3         .prefetch(batch_size)\cb1 \
\
\
\pard\pardeftab720\sl380\partightenfactor0
\cf5 \cb3 \strokec5 def\cf4 \strokec4  build_model():\cb1 \
\pard\pardeftab720\sl380\partightenfactor0
\cf4 \cb3     base_model = tf.keras.applications.MobileNetV2(\cb1 \
\cb3                                   include_top=\cf5 \strokec5 False\cf4 \strokec4 ,\cb1 \
\cb3                                   weights=\cf2 \strokec2 'imagenet'\cf4 \strokec4 )\cb1 \
\cb3     global_average_layer =  tf.keras.layers.GlobalAveragePooling2D()     \cb1 \
\cb3     prediction_layer =    tf.keras.layers.Dense(\cf6 \strokec6 6\cf4 \strokec4 , activation=tf.keras.activations.softmax)\cb1 \
\cb3     base_model.trainable = \cf5 \strokec5 False\cf4 \cb1 \strokec4 \
\cb3     inputs = tf.keras.Input(shape=(\cf6 \strokec6 224\cf4 \strokec4 , \cf6 \strokec6 224\cf4 \strokec4 , \cf6 \strokec6 3\cf4 \strokec4 ))\cb1 \
\cb3     x = base_model(inputs, training=\cf5 \strokec5 False\cf4 \strokec4 )\cb1 \
\cb3     x = global_average_layer(x)\cb1 \
\cb3     x = tf.keras.layers.Dropout(\cf6 \strokec6 0.2\cf4 \strokec4 )(x)\cb1 \
\cb3     x = tf.keras.layers.Flatten()(x)\cb1 \
\cb3     outputs = prediction_layer(x)\cb1 \
\cb3     model = tf.keras.Model(inputs, outputs)\cb1 \
\
\cb3     \cf5 \strokec5 return\cf4 \strokec4  model\cb1 \
\
\
\pard\pardeftab720\sl380\partightenfactor0
\cf5 \cb3 \strokec5 def\cf4 \strokec4  exp_decay(epoch, lr):\cb1 \
\pard\pardeftab720\sl380\partightenfactor0
\cf4 \cb3     \cf5 \strokec5 if\cf4 \strokec4  epoch < \cf6 \strokec6 10\cf4 \strokec4 :\cb1 \
\cb3       \cf5 \strokec5 return\cf4 \strokec4  lr\cb1 \
\cb3     \cf5 \strokec5 else\cf4 \strokec4 :\cb1 \
\cb3       \cf5 \strokec5 return\cf4 \strokec4  lr * tf.math.exp(\cf6 \strokec6 -0.1\cf4 \strokec4 )\cb1 \
\
\
\pard\pardeftab720\sl380\partightenfactor0
\cf5 \cb3 \strokec5 def\cf4 \strokec4  main():\cb1 \
\pard\pardeftab720\sl380\partightenfactor0
\cf4 \cb3     args = argparse.ArgumentParser()\cb1 \
\cb3     args.add_argument(\cf2 \strokec2 '--train'\cf4 \strokec4 , \cf5 \strokec5 type\cf4 \strokec4 =\cf5 \strokec5 str\cf4 \strokec4 , \cf5 \strokec5 help\cf4 \strokec4 =\cf2 \strokec2 'Glob pattern to collect train tfrecord files'\cf4 \strokec4 )\cb1 \
\cb3     args.add_argument(\cf2 \strokec2 '--test'\cf4 \strokec4 , \cf5 \strokec5 type\cf4 \strokec4 =\cf5 \strokec5 str\cf4 \strokec4 , \cf5 \strokec5 help\cf4 \strokec4 =\cf2 \strokec2 'Glob pattern to collect test tfrecord files'\cf4 \strokec4 )\cb1 \
\cb3     args = args.parse_args()\cb1 \
\
\cb3     train_dataset = create_dataset(glob.glob(args.train), BATCH_SIZE)\cb1 \
\cb3     validation_dataset = create_dataset(glob.glob(args.test), BATCH_SIZE)\cb1 \
\
\cb3     model = build_model()\cb1 \
\
\cb3     model.\cf5 \strokec5 compile\cf4 \strokec4 (\cb1 \
\cb3         optimizer=tf.optimizers.Adam(lr = \cf6 \strokec6 0.00001\cf4 \strokec4 ),\cb1 \
\cb3         loss=tf.keras.losses.categorical_crossentropy,\cb1 \
\cb3         metrics=[tf.keras.metrics.categorical_accuracy],\cb1 \
\cb3     )\cb1 \
\
\cb3     log_dir=\cf2 \strokec2 '/content/drive/My Drive/log15'\cf4 \strokec4 .\cf5 \strokec5 format\cf4 \strokec4 (LOG_DIR, time.time())\cb1 \
\cb3     model.fit(\cb1 \
\cb3         train_dataset,\cb1 \
\cb3         epochs=\cf6 \strokec6 50\cf4 \strokec4 ,\cb1 \
\cb3         validation_data=validation_dataset,\cb1 \
\cb3         callbacks=[\cb1 \
\cb3             tf.keras.callbacks.TensorBoard(log_dir),\cb1 \
\cb3             tf.keras.callbacks.LearningRateScheduler(exp_decay, verbose = \cf6 \strokec6 1\cf4 \strokec4 ),\cb1 \
\cb3         ]\cb1 \
\cb3     )\cb1 \
\
\
\pard\pardeftab720\sl380\partightenfactor0
\cf5 \cb3 \strokec5 if\cf4 \strokec4  __name__ == \cf2 \strokec2 '__main__'\cf4 \strokec4 :\cb1 \
\pard\pardeftab720\sl380\partightenfactor0
\cf4 \cb3     main()\cb1 \
\
}